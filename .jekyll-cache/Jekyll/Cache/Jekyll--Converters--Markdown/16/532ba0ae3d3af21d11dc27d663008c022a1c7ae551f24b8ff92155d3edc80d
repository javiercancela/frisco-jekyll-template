I"f<p>Seguimos con algunos conceptos estad√≠sticos √∫tiles para estudiar el modelo de regresi√≥n log√≠stica.</p>

<h3 id="predicci√≥n-de-categor√≠as">Predicci√≥n de categor√≠as</h3>

<p>La principal caracter√≠stica de la regresi√≥n log√≠stica es que la variable respuesta es una categor√≠a, no un valor continuo. Siguiendo con el ejemplo de la entrada anterior, la regresi√≥n log√≠stica nos permitir√≠a relacionar las horas dedicadas al estudio con la categor√≠a final de la nota: suspenso o aprobado. Este tipo de regresi√≥n log√≠stica, con dos posibles categor√≠as para el resultado, se llama regresi√≥n log√≠stica binaria.</p>

<p>La regresi√≥n log√≠stica estima la probabilidad de que una caracter√≠stica est√© presente en la muestra para los valores de las variables predictoras dadas. Estos valores pueden ser continuos, discretos, categ√≥ricos o una mezcla de varios. En el caso de que queramos estimar la probabilidad de que una persona desarrolle c√°ncer de pulm√≥n (y por lo tanto predecir, por ejemplo, si lo va a desarrollar en los pr√≥ximos 5 a√±os), podr√≠amos utilizar como factores predictores el tiempo que lleva fumando (una variable continua), la cantidad de cigarrillos (una variable discreta), y si tiene o no antecedentes familiares (una categor√≠a con dos posibles valores).</p>

<p>Todos esos factores se incorporar√≠an al modelo de la siguiente forma. Sea \(Y\) la variable respuesta. Para una persona (muestra) \(i\), existen dos posibles valores:</p>

\[Y_i = 1 \rightarrow \text{  la persona desarrollar√° la enfermedad}\]

\[Y_i = 0 \rightarrow \text{  la persona no desarrollar√° la enfermedad}\]

<p>El conjunto de variables predictoras lo modelaremos a trav√©s de \(X = (X_1, X_2, ..., X_k)\), donde \(x_i\) es el valor observado para la persona (muestra) \(i\). Para simplificar el modelo, nos centraremos en una √∫nica variable predictora \(X\). El modelo intentar√° encontrar la probabilidad de que la persona desarrolle la enfermedad (\(Y_i=1\)) para un valor predictor concreto (\(X_i=x_i\)):</p>

\[\pi_i=Pr(Y_i=1|X_i=x_i) \text{  (1)}\]

<h3 id="la-funci√≥n-log√≠stica">La funci√≥n log√≠stica</h3>

<p>La <a href="https://es.wikipedia.org/wiki/Funci%C3%B3n_log%C3%ADstica">funci√≥n log√≠stica</a> es la curva definida por la siguiente ecuaci√≥n:</p>

\[f(x)=\dfrac{L}{1+e^{-k(x-x_0)}}\]

<p>Un caso especial de esta funci√≥n es la <a href="https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide">funci√≥n sigmoidea</a>, donde \(L=1\), \(k=1\) y \(x_0=0\):</p>

\[f(x)=\dfrac{1}{1+e^{-x}} \text{  (2)}\]

<div style="text-align:center">
    <figure>
        <img alt="Funci√≥n sigmoidea sacada de la wikipedia" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/600px-Logistic-curve.svg.png" />
        <figcaption>Funci√≥n sigmoidea sacada de la wikipedia</figcaption>
    </figure>
</div>

<p>Este tipo de funci√≥n tiene m√∫ltiples usos en distintas disciplinas cient√≠ficas. En nuestro caso, nos interesa porque los valores de \(f(x)\) tienen a \(L\) o \(-L\) seg√∫n \(x\) tiene a \(\infty\) o \(-\infty\). Si \(L=1\), se puede interpretar que esta funcion asigna una probabilidad a un suceso en funci√≥n de \(x\). En el caso de una red neuronal, la entrada neta al sistema no ser√° \(x\), sino \(z=w_0x_0+w_1x_1\) (para el caso de una √∫nica variable predictora), que podemos simplificar como \(\beta_0 + \beta_1x\). Por tanto, de \(\text{(1)}\) y \(\text{(2)}\):</p>

\[Pr(Y_i=1|Z_i=z_i)=\phi(z)=\dfrac{1}{1+e^{-z}}\]

<p>y multiplicando arriba y abajo por \(e^z\):</p>

\[\phi(z)=\dfrac{e^z}{1+e^z}\]

<p>Como los valores de \(\phi(z)\) van a variar entre 0 y 1, podemos establecer como regla para categorizar muestras que la categor√≠a predicha \(\hat y\) valdr√°:</p>

\[\hat y = \begin{cases}
\text{1 si } \phi(z) \ge 0.5 \cr
\text{-1 en otro caso}
\end{cases}\]

<p>Utilizaremos estas ideas en la siguiente entrada para plantear el algoritmo de regresi√≥n lineal.</p>

:ET