I"÷V<p>El perceptr√≥n visto en el post anterior es una red neuronal de una sola capa. Otro ejemplo de este tipo de redes es la llamada <strong>neurona lineal adaptativa</strong>, en ingl√©s <em>ADAptative LIneal NEuron</em>, o <a href="https://es.wikipedia.org/wiki/Adaline"><em>ADALINE</em></a>. Nos dice el libro que la importancia de este algoritmo se debe a que muestra con claridad la definici√≥n y minimizaci√≥n de las funciones de costos (<em>cost functions</em>).</p>

<h2 id="funci√≥n-de-costos">Funci√≥n de costos</h2>
<p><strong>Funci√≥n de costos</strong> es un t√©rmino que procede de la econom√≠a, y hace referencia a la funci√≥n que expresa los costes de producci√≥n en t√©rminos de la cantidad producida. En el campo de las redes neuronales la funci√≥n de costos devuelve un n√∫mero que determina indica lo bien que el algoritmo genera las salidas correctas para las muestras de entrenamiento. Este n√∫mero es mejor cuanto m√°s bajo, por eso se busca minimizar el valor de la funci√≥n. Esta minimizaci√≥n de la funci√≥n de costos supone la base de muchas t√©cnicas de clasificaci√≥n.</p>

<p>La diferencia b√°sica entre Adaline y el perceptr√≥n est√° en la funci√≥n de activaci√≥n, que pasa de ser una funci√≥n escal√≥n a ser una funci√≥n lineal.</p>

<div style="text-align:center">
    <figure>
        <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/images/02_09.png"><img alt="Actualizamos los pesos con una funci√≥n lineal de la entrada" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_09.png" /></a>
        <figcaption>Actualizamos los pesos con una funci√≥n lineal de la entrada</figcaption>
    </figure>
</div>

<p>En concreto, la funci√≥n lineal de activaci√≥n de Adaline es la funci√≥n identidad \(\phi(z) = z\), con lo que \(\phi(\mathbf{w}^T\bf x) = \mathbf{w}^T\bf x\). Como vemos en la gr√°fica superior, se sigue usando un cuantizador para clasificar la muestra, aunque no se use ya para corregir los pesos.</p>

<h2 id="minimizaci√≥n-de-funciones-de-costos">Minimizaci√≥n de funciones de costos</h2>

<p>Igual que en el caso del perceptr√≥n, la actualizaci√≥n de pesos se realiza calculando \(w_j := w_j + \eta(y^{(i)} - \hat y^{(i)})x_j^{(i)}\). Para el perceptr√≥n tanto \(y^{(i)}\) como \(\hat y^{(i)}\) son etiquetas de clases con solo dos posibles valores. En el caso de Adaline se usan valores continuos.</p>

<p><a name="1"></a></p>

<p>La idea de la funci√≥n de costos es definir una funci√≥n que se pueda optimizar durante el proceso de aprendizaje. Para ello utilizamos la suma de los errores al cuadrado (<em>Sum of Squared Errors</em>, o <em>SSE</em>, tambi√©n llamado en ingl√©s <a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares"><em>Residual Sum of Squareds</em></a>):</p>

\[J({\mathbf{w}}) = \frac{1}{2} \sum_i \big(y^{(i)} - \phi(z)_{A}^{(i)}\big)^2,\]

<p>donde \(\frac{1}{2}\) se incluye para simplificar c√°lculos posteriores. Como buscamos el \(\mathbf{w}\) que minimiza el valor de esa funci√≥n, multiplicarla por una constante no afecta al resultado. Como siempre, \(y^{(i)}\) es el resultado esperado para la muestra \(i\). \(\phi(z)_{A}^{(i)}\) es la salida de la funci√≥n de activaci√≥n (\(A\)) para la muestra \(i\).</p>

<p>Esta funci√≥n es diferenciable y convexa, lo que nos permite calcular un m√≠nimo. Como nuestra funci√≥n de costos s√≥lo depende de los pesos \(\mathbf{w}\), minimizarla nos dar√° el peso que tenga una menor diferencia entre la salida esperada y la obtenida (\(y^{(i)} - \phi(z)_{A}^{(i)}\)). Para calcular el m√≠nimo se usa un algoritmo llamado <a href="http://alejandrosanchezyali.blogspot.co.uk/2016/01/algoritmo-del-gradiente-descendente-y.html">gradiente descendente</a>.</p>

<p>Nuestro objetivo, como siempre, es ajustar el peso \(\mathbf{w}\) en incrementos \(\Delta \mathbf{w}\):</p>

\[\mathbf{w} := \mathbf{w} + \Delta \mathbf{w}.\]

<p>Para calcular \(\Delta \mathbf{w}\) vamos a necesitar conocer el gradiente de nuestra funci√≥n de costos: \(\nabla J(\mathbf{w})\). <a href="https://es.wikipedia.org/wiki/Gradiente">Gradiente</a> es un t√©rmino matem√°tico que hace referencia al vector que indica la direcci√≥n en la que un campo var√≠a con m√°s rapidez. Para una funci√≥n de \(k\) variables el gradiente es el vector de \(k\) dimensiones que marca la direcci√≥n en la que la funci√≥n se incrementa m√°s r√°pidamente.</p>

<div style="text-align:center">
    <figure>
        <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/images/02_10.png"><img alt="Usamos el gradiente en cada punto para calcular los decrementos que nos lleven al m√≠nimo" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_10.png" /></a>
        <figcaption>Usamos el gradiente en cada punto para calcular los decrementos que nos lleven al m√≠nimo</figcaption>
    </figure>
</div>

<p>Nosotros vamos a usar el gradiente para buscar el m√≠nimo de \(J(\mathbf{w})\), as√≠ que en vez de sumarlo lo restaremos (de ah√≠ lo de gradiente descendente). Adem√°s usaremos nuestra tasa de aprendizaje para modular esta iteraci√≥n:</p>

\[\Delta \mathbf{w} = - \eta \nabla J(\mathbf{w}).\]

<p>Dado que</p>

\[J({\mathbf{w}}) = \frac{1}{2} \sum_i \big(y^{(i)} - \phi(z)_{A}^{(i)}\big)^2,\]

<p>tendremos que cada uno de los pesos se actualizar√° con este incremento:</p>

\[\Delta w_{j} := \eta \sum_i \big(y^{(i)} - \phi(z)_{A}^{(i)}\big) x_{j}^{(i)}.\]

<p>Para una explicaci√≥n del c√°lculo de este gradiente podemos leer <a href="http://rasbt.github.io/mlxtend/user_guide/general_concepts/linear-gradient-derivative/">este art√≠culo del propio Sebastian Raschka</a>.</p>

<h2 id="adaline-en-python">Adaline en Python</h2>

<p>Como en la entrada anterior, el c√≥digo est√° <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb">sacado de GitHub</a>.</p>

<p>La implementaci√≥n de Adaline es muy similar a la del Perceptr√≥n. La √∫nica diferencia est√° en el m√©todo <code class="language-plaintext highlighter-rouge">fit</code>, donde los pesos se actualizan con el gradiente descendente</p>

<pre class="line-numbers">
  <code class="language-python">
	class AdalineGD(object):
	    def __init__(self, eta=0.01, n_iter=50):
	        self.eta = eta
	        self.n_iter = n_iter

	    def fit(self, X, y):
	        self.w_ = np.zeros(1 + X.shape[1])
	        self.cost_ = []

	        for i in range(self.n_iter):
	            output = self.activation(X)
	            errors = (y - output)
	            self.w_[1:] += self.eta * X.T.dot(errors)
	            self.w_[0] += self.eta * errors.sum()
	            cost = (errors**2).sum() / 2.0
	            self.cost_.append(cost)
	        return self

	    def net_input(self, X):
	        return np.dot(X, self.w_[1:]) + self.w_[0]

	    def activation(self, X):
	        return self.net_input(X)

	    def predict(self, X):
	        return np.where(self.activation(X) &gt;= 0.0, 1, -1)
  </code>
</pre>

<p>Recordemos c√≥mo funciona el m√©todo <code class="language-plaintext highlighter-rouge">fit</code>. Se le pasan dos par√°metros: una matriz \(\bf X\), que contiene una fila por cada muestra y una columna por cada caracter√≠stica, y que constituye nuestro conjunto de datos de entrenamiento; y un array \(\bf y\), que contiene el resultado objetivo para cada muestra.</p>

<p>Lo primero que hace el m√©todo <code class="language-plaintext highlighter-rouge">fit</code> es inicializar los pesos y los costos:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">self</span><span class="p">.</span><span class="n">w_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="bp">self</span><span class="p">.</span><span class="n">cost_</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></div>
<p>Despu√©s iteramos el proceso tantas veces como √©pocas se hayan definido. La entrada neta (la funci√≥n <code class="language-plaintext highlighter-rouge">net_input</code>) es el producto escalar de los atributos de las muestras y sus pesos. Para la salida utilizamos una funci√≥n <code class="language-plaintext highlighter-rouge">activation</code> que es igual a la entrada neta. La existencia de este m√©todo se justifica para hacer el c√≥digo m√°s general, y poder reutilizarlo con otros algoritmos. En nuestro caso, esta funci√≥n es la funci√≥n identidad, por lo que podr√≠amos haber usado directamente <code class="language-plaintext highlighter-rouge">net_input</code>. El error ser√° la difencia entre la salida esperada, <code class="language-plaintext highlighter-rouge">y</code>, y la real, <code class="language-plaintext highlighter-rouge">output</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">errors</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>Si recordamos las entradas anteriores, la salida esperada <code class="language-plaintext highlighter-rouge">y</code> es un array con las clases reales de 100 muestras, las 50 primeras con valor -1 (Iris-setosa), y las 50 siguientes con valor 1 (Iris-versicolor). El valor de output es la salida de la funci√≥n identidad, pero en este caso vamos a considerar todas las muestras a la vez, con lo que tendremos un array de 100 elementos en vez de un escalar. El m√©todo <code class="language-plaintext highlighter-rouge">net_input</code> calcula el producto escalar de la matriz de muestras <code class="language-plaintext highlighter-rouge">X</code> por el array de pesos <code class="language-plaintext highlighter-rouge">w_</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">net_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

</code></pre></div></div>

<h3 id="c√°lculo-de-errores">C√°lculo de errores</h3>

<p>El resultado es un array de errores (<code class="language-plaintext highlighter-rouge">errors</code>) de 100 elementos, uno para cada muestra. Con ellos se actualizan los pesos:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">self</span><span class="p">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">eta</span> <span class="o">*</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
<span class="bp">self</span><span class="p">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">eta</span> <span class="o">*</span> <span class="n">errors</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<p>En la primera l√≠nea se aplica un incremento <code class="language-plaintext highlighter-rouge">self.eta * X.T.dot(errors)</code> al array de pesos \(\mathbf{w}\), salvo al elemento \(w_0\) (peso asociado a una entrada ficticia \(x_0 = 1\) para simplificar los c√°lculos). Recordando la f√≥rmula de incremento de pesos vista m√°s arriba:</p>

\[\Delta w_{j} := \eta \sum_i \big(y^{(i)} - \phi(z)_{A}^{(i)}\big) x_{j}^{(i)},\]

<p>tenemos que los elementos \(error^{(i)}\) del array <code class="language-plaintext highlighter-rouge">errors</code> se corresponden con \(error^{(i)} = y^{(i)} - \phi(z)_{A}^{(i)}\). Por lo tanto, el producto escalar entre la traspuesta de la matriz de atributos de cada muestra <code class="language-plaintext highlighter-rouge">X</code> y el array de errores <code class="language-plaintext highlighter-rouge">errors</code> (<code class="language-plaintext highlighter-rouge">X.T.dot(errors)</code>) se corresponden con el sumatorio \(\sum_i \big(y^{(i)} - \phi(z)_{A}^{(i)}\big) x_{j}^{(i)}\).</p>

<p>Para el caso del elemento \(w_0\), al ser el valor de los atributos de esa muestra ficticia igual a uno, basta con sumar los errores para obtener el incremento de peso (tambi√©n podr√≠amos haber a√±adido una fila con valores unitarios a la matriz <code class="language-plaintext highlighter-rouge">X</code>).</p>

<p>Aunque el algoritmo no usa la funci√≥n de costos directamente, ya que el ajuste de pesos se realiza mediante el gradiente descendente que acabamos de aplicar y que se explica m√°s arriba, vamos a almacenar tambi√©n el valor de la funci√≥n para dibujar despu√©s su evoluci√≥n.</p>

<h3 id="c√°lculo-de-costos">C√°lculo de costos</h3>

<p>Recordemos la funci√≥n de costos:</p>

\[J({\mathbf{w}}) = \frac{1}{2} \sum_i \big(y^{(i)} - \phi(z)_{A}^{(i)}\big)^2.\]

<p>El programa almacena un arrary <code class="language-plaintext highlighter-rouge">errors = (y - output)</code> que se corresponde con \(y^{(i)} - \phi(z)_{A}^{(i)}\), as√≠ que para calcular en valor de la funci√≥n s√≥lo tenemos que sumar el cuadrado de los valores del array y dividir entre dos. Esto nos dar√° el valor calculado por la funci√≥n de costos para los pesos actuales. Como estamos iterando mediante el gradiente descendente vamos a almacenar los resultados de la funci√≥n obtenidos para cada conjunto de pesos:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cost</span> <span class="o">=</span> <span class="p">(</span><span class="n">errors</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.0</span>
<span class="bp">self</span><span class="p">.</span><span class="n">cost_</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</code></pre></div></div>

<p>Una vez definida la clase, el libro pasa a utilizarla con dos tasas de aprendizaje distintas. Esta tasa va a determinar la convergencia del algoritmo, y encontrar el valor que nos de la mejor convergencia posible requiere muchas pruebas. Vamos a probar con \(\eta = 0.1\) y \(\eta = 0.0001\):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">ada1</span> <span class="o">=</span> <span class="n">AdalineGD</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ada1</span><span class="p">.</span><span class="n">cost_</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">log10</span><span class="p">(</span><span class="n">ada1</span><span class="p">.</span><span class="n">cost_</span><span class="p">),</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Epochs'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'log(Sum-squared-error)'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Adaline - Learning rate 0.01'</span><span class="p">)</span>

<span class="n">ada2</span> <span class="o">=</span> <span class="n">AdalineGD</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ada2</span><span class="p">.</span><span class="n">cost_</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ada2</span><span class="p">.</span><span class="n">cost_</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Epochs'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Sum-squared-error'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Adaline - Learning rate 0.0001'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>Pintamos una gr√°fica con cada tasa, representado la evoluci√≥n del valor de la funci√≥n de costos para cada iteraci√≥n (√©poca). Para la tasa de 0.1 representamos en realidad el logaritmo del valor, ya que el valor real diverge exponencialmente. En cambio, podemos ver como la tasa de 0.0001 converge, pero lentamente.</p>

<div style="text-align:center">
    <figure>
        <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/images/02_11.png"><img alt="Una tasa de aprendizaje muy alta provoca que el algoritmo no converja, una tasa muy baja provoca que converja lentamente" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_11.png" /></a>
        <figcaption>Una tasa de aprendizaje muy alta provoca que el algoritmo no converja, una tasa muy baja provoca que converja lentamente</figcaption>
    </figure>
</div>

<p>Llevado al ejemplo visual del gradiente descendente, vemos que la tasa de aprendizaje influye en la longitud del ‚Äúpaso‚Äù que se da hacia el m√≠nimo. Si este paso es muy grande el algoritmo ‚Äúse sale‚Äù:</p>

<div style="text-align:center">
    <figure>
        <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/images/02_12.png"><img alt="Visualizaci√≥n gr√°fica de los pasos dados con el algoritmo" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_12.png" /></a>
        <figcaption>Visualizaci√≥n gr√°fica de los pasos dados con el algoritmo</figcaption>
    </figure>
</div>

<p>El libro acaba esta parte con una referencia al escalado de caracter√≠sticas que se ver√° en el tema 3, y que nosotros dejaremos hasta entonces.</p>

<p>En la pr√≥xima entrada veremos c√≥mo modificar este algoritmo para adaptarlo a grandes grupos de datos.</p>

:ET