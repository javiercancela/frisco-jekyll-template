<!DOCTYPE html>

<html lang="en">
	<head>
		<script type="text/javascript">
		    var host = "www.javiercancela.com";
		    if ((host == window.location.host) && (window.location.protocol != "https:"))
		        window.location.protocol = "https";
		</script>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="generator" content="Jekyll v3.3.1">

		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300|Rubik:300">
		<link rel="stylesheet" href="/css/screen.css">
		<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
		<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
		<link rel="manifest" href="/manifest.json">
		<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
		<meta name="theme-color" content="#ffffff">

		<!-- Begin Jekyll SEO tag v2.1.0 -->
<title>Machine Learning con Python - Tema 2 - El perceptrón - Página de Javier Cancela</title>
<meta property="og:title" content="Machine Learning con Python - Tema 2 - El perceptrón" />
<meta name="description" content="Notas sobre el libro “Python Machine Learning”, de Sebastian Raschka" />
<meta property="og:description" content="Notas sobre el libro “Python Machine Learning”, de Sebastian Raschka" />
<link rel="canonical" href="https://www.javiercancela.com/2017/03/19/python-machine-learning-ii/" />
<meta property="og:url" content="https://www.javiercancela.com/2017/03/19/python-machine-learning-ii/" />
<meta property="og:site_name" content="Página de Javier Cancela" />
<meta property="og:image" content="https://www.javiercancela.com/images/pml/pml.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-03-19T01:00:00+00:00" />
<script type="application/ld+json">
{"@context": "http://schema.org",
"@type": "BlogPosting",
"headline": "Machine Learning con Python - Tema 2 - El perceptrón",
"image": "https://www.javiercancela.com/images/pml/pml.jpg",
"datePublished": "2017-03-19T01:00:00+00:00",
"description": "Notas sobre el libro “Python Machine Learning”, de Sebastian Raschka",
"publisher": {"@type": "Organization",
"logo": {"@type": "ImageObject",
"url": "https://www.javiercancela.com/siteicon.png"}},
"url": "https://www.javiercancela.com/2017/03/19/python-machine-learning-ii/"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="https://www.javiercancela.com/feed.xml" title="Página de Javier Cancela" />

		
			<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-58458863-1', 'auto');
  ga('send', 'pageview');

</script>
		
	</head>

	<body>
		<header id="mainHeader">
			<div class="container">
				<div class="company-name">
					<a href="/">
						<span class="dark-logo"><img width="104" height="38" src="/images/logo/dark.png" alt="dark frisco logo"></span>
						<span class="light-logo"><img width="104" height="38" src="/images/logo/light.png" alt="light frisco logo"></span>
					</a>
				</div>
				<nav>
	<a class="nav-toggle" id="open-nav" href="#">&#9776;</a>
	
		
		

		
		<a href="/" class="" >Blog</a>
	
		
		

		
		<a href="/archivo/" class="" >Archivo</a>
	
		
		

		
		<a href="/sobre-mi/" class="" >Sobre mí</a>
	
</nav>

			</div>
		</header>

		<section class="hero" style="background-image: url(/images/pml/pml.jpg)">
	<div class="inner-hero text-container">
		<div class="hero-text-container">
			<h1>Machine Learning con Python - Tema 2 - El perceptrón</h1>
			<p class="subtext">Notas sobre el libro "Python Machine Learning", de Sebastian Raschka</p>
		</div>
	</div>
</section>

<section>
	<div class="blog-post text-container">
		<p class="post-details">
	
		
		<span class="blog-filter">
			<a href="/category/python/">Python</a>
		</span>
	
		
		<span class="blog-filter">
			<a href="/category/libros/">Libros</a>
		</span>
	
		
		<span class="blog-filter">
			<a href="/category/machine-learning/">Machine Learning</a>
		</span>
	
		
		<span class="blog-filter">
			<a href="/category/inteligencia-artificial/">Inteligencia Artificial</a>
		</span>
	
	
	
	
	
	
	
	<span class="post-date">19 de marzo de 2017</span>
</p>


		<div class="post-content">
			<p>Empezamos con los algoritmos. Vamos a implementar un perceptrón en Python, y entrenarlo para que sepa clasificar las diferentes especies de flores en Iris. El libro comienza mostrando el <a href="https://es.wikipedia.org/wiki/Neurona_de_McCulloch-Pitts">modelo de neurona de McCulloch-Pitts</a>:</p>

<div style="text-align:center">
    <figure>
        <img alt="En este modelo se emite una señal de salida si el resultado de aplicar una función a la suma de las entradas supera cierto umbral" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_01.png" />
        <figcaption>En este modelo se emite una señal de salida si el resultado de aplicar una función a la suma de las entradas supera cierto umbral</figcaption>
    </figure>
</div>

<p>Tomando este modelo como base, Frank Rosenblatt diseñó un dispositivo electrónico con capacidad para aprender. El algoritmo usado por ese dispositivo se conoce como Perceptrón.</p>

<h2 id="perceptrón">Perceptrón</h2>

<p>El <a href="https://es.wikipedia.org/wiki/Perceptr%C3%B3n">perceptrón</a> es un algoritmo de aprendizaje supervisado para realizar tareas de clasificación binaria, es decir, para determinar si una muestra pertenece o no a una clase.</p>

<div style="background-color: #EEEEEE; padding: 1em">
El libro asume cierta familiaridad trabajando con vectores y matrices. Para refrescar conceptos recomiendo revisar los <a href="https://es.wikipedia.org/wiki/%C3%81lgebra_lineal#Enlaces_externos">enlaces externos referenciados en la página de la Wikipedia dedicada al Álgebra Lineal</a>. También tiene buena pinta [el curso de la Khan Academy](https://es.khanacademy.org/math/linear-algebra). <br />
En inglés hay varios libros gratuitos disponibles, como [este](https://www.math.ucdavis.edu/~linear/linear-guest.pdf) y [este](http://www.cs.cmu.edu/~zkolter/course/linalg/linalg_notes.pdf).
</div>

<div style="text-align:center">
    <figure>
        <a href="https://commons.wikimedia.org/wiki/File:Perceptr%C3%B3n_5_unidades.svg#/media/File:Perceptr%C3%B3n_5_unidades.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Perceptr%C3%B3n_5_unidades.svg/1200px-Perceptr%C3%B3n_5_unidades.svg.png" alt="Perceptrón 5 unidades.svg" /></a>
        <figcaption>
            De <a href="//commons.wikimedia.org/w/index.php?title=User:Alejandro.cartas&amp;action=edit&amp;redlink=1" class="new" title="User:Alejandro.cartas (page does not exist)">Alejandro Cartas</a> - <span class="int-own-work" lang="es">Trabajo propio</span>, <a href="http://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons Attribution-Share Alike 4.0">CC BY-SA 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=41534843">Enlace</a>
        </figcaption>
    </figure>
</div>

<p>Como podemos ver en la figura anterior, la señal de entrada está compuesta por un array <script type="math/tex">\bf x</script> al que se aplica una serie de pesos definidos por un array <script type="math/tex">\bf w</script>. Es decir, cada elemento <script type="math/tex">x_i</script> se multiplica por <script type="math/tex">w_i</script>, y se suma el resultado de cada uno de estos productos. De una manera más formal, definimos</p>

<script type="math/tex; mode=display">x = \begin{bmatrix}
x_1 \cr
\vdots \cr
x_m \cr
\end{bmatrix}, w = \begin{bmatrix}
w_1 \cr
\vdots \cr
w_m \cr
\end{bmatrix}
\tag{2.1}</script>

<p>Y la entrada resultante <script type="math/tex">z</script> será la suma de cada entrada ponderada:</p>

<script type="math/tex; mode=display">z = \sum{w_ix_i} = w_1x_1 + \cdots + w_mx_m
\tag{2.2}</script>

<p>Ya tenemos la entrada <script type="math/tex">z</script> a la función de activación <script type="math/tex">\phi(z)</script>. Para nuestro caso vamos a usar como función de activación la <a href="https://es.wikipedia.org/wiki/Funci%C3%B3n_escal%C3%B3n_de_Heaviside">función escalón</a>. Esta función se define de la siguiente forma:</p>

<script type="math/tex; mode=display">\phi(z) = \begin{cases}
\text{1 si } z \ge \theta \cr
\text{-1 en otro caso}
\end{cases}
\tag{2.3}</script>

<p>Ese valor <script type="math/tex">\theta</script> es el umbral que tiene que superar <script type="math/tex">z</script> para disparar la señal. Para simplificar los cálculos, definimos un peso 0 con <script type="math/tex">w_0 = -\theta</script> y <script type="math/tex">x_0 = 1</script>, de esta forma podemos escribir:</p>

<script type="math/tex; mode=display">z = w_0x_0 + w_1x_1 + \cdots + w_mx_m
\tag{2.4}
\label{2.4}</script>

<p>y</p>

<script type="math/tex; mode=display">\phi(z) = \begin{cases}
\text{1 si } z \ge 0 \cr
\text{-1 en otro caso}
\end{cases}
\tag{2.5}
\label{2.5}</script>

<p>El valor de <script type="math/tex">z</script> se puede escribir también como <script type="math/tex">z = \mathbf{w}^T\bf x</script>. El superíndice T indica que la matriz (en este caso un array, que tratamos como una matriz de 1 columna y n filas) está traspuesta, o lo que es lo mismo, se han convertidos sus columnas en filas. Por lo tanto:</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathbf{w}^T\bf x = \begin{bmatrix} w_0 & w_1 & \cdots & w_m \end{bmatrix} \begin{bmatrix}
x_1 \cr
\vdots \cr
x_m \cr
\end{bmatrix}

\tag{2.6} %]]></script>

<p>Esto nos permite usar la operación de producto escalar entre matrices. En una operación entre matrices, si la primera tiene dimensiones <script type="math/tex">n \times m</script>, la segunda debe tener <script type="math/tex">m \times p</script>, dando como resultado una matriz <script type="math/tex">n \times p</script>. En nuestro caso, la dimensiones serían <script type="math/tex">1 \times n</script> y <script type="math/tex">n \times 1</script>, dando como resultado una matriz <script type="math/tex">1 \times 1</script>, es decir, un escalar. Por ello esta operación es realmente un producto escalar entre vectores, cuyo resultado es la ya conocida expresión \eqref{2.4}</p>

<h2 id="entrenando-el-modelo">Entrenando el modelo</h2>

<p>Pretendemos modificar los valores de los pesos (<script type="math/tex">\mathbf{w}</script>) de forma que las salidas del preceptrón se vayan acercando a los valores esperados. Para ello se inicializan los pesos a cero, o a un valor muy pequeño, se obtiene la salida, y se actualizan los pesos.</p>

<p>¿Cómo se actualizan los pesos? Sumándoles una cantidad (positiva o negativa) que depende de la entrada, de la diferencia entre la salida real y la salida esperada, y de la tasa de aprendizaje (<script type="math/tex">\eta</script>), que es una constante que vale entre 0 y 1:</p>

<script type="math/tex; mode=display">\Delta w_j = \eta(y^{(i)} - \hat y^{(i)})x_j^{(i)}
\tag{2.7}</script>

<p>En esta fórmula <script type="math/tex">y^{(i)}</script> es la clase a la que pertenece la muestra (i), <script type="math/tex">\hat y^{(i)}</script> es la clase predicha por el perceptrón, y <script type="math/tex">x_j^{(i)}</script> es la entrada de la característica j para la muestra (i). Todo esto se multiplica para calcular la variación en la característica j: <script type="math/tex">\Delta w_j</script>. Con cada muestra se recalculan los pesos:</p>

<script type="math/tex; mode=display">w_j := w_j + \Delta w_j
\tag{2.8}</script>

<h3 id="condiciones-de-convergencia">Condiciones de convergencia</h3>

<p>Este proceso iterativo puede converger o no. Para que el perceptrón clasifique correctamente las muestras , el valor de <script type="math/tex">w_j</script> debe ir acercándose cada vez más a un valor final, o lo que es lo mismo, <script type="math/tex">\Delta w_j</script> debe tender a cero.</p>

<p>Para que se de esta situación deben cumplirse dos requisitos. En primer lugar, la tasa de aprendizaje debe ser suficientemente pequeña. En general, cuanto más grande sea <script type="math/tex">\eta</script> más rápido será el aprendizaje, pero pasado cierto valor el proceso de aprendizaje nunca convergerá. En segundo lugar, las dos clases deben ser linealmente separables. Es decir, si representamos los elementos de ambas clases en un diagrama de 2 dimensiones (suponeniendo que las muestras tienen dos características), debe existir una línea que separe a todos los de una clase a un lado, y a todos los de la otra clase al otro lado.</p>

<div style="text-align:center">
    <figure>
        <img alt="Ejemplos con muestras de dos clases. Sólo el primero es linearmente separable." src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_03.png" />
        <figcaption>Ejemplos con muestras de dos clases. Sólo el primero es linearmente separable.</figcaption>
    </figure>
</div>

<h2 id="perceptrón-en-python">Perceptrón en Python</h2>

<p>El código del capítulo 2 (y de los demás capítulos) está, como comentamos, <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb">subido a GitHub</a> en formato <a href="http://jupyter.org/">Jupyter</a>. Jupyter (originalmente iPython) es una aplicación web que permite crear y compartir documentos que contengan código, gráficas, animaciones… de un forma muy sencilla. Jupyter viene incluido en Anaconda, que es el entorno Python que recomendamos en <a href="/2017/03/12/python-machine-learning-i/">una entrada anterior</a>. También se puede ver el código completo de cada capítulo como archivo Python <a href="https://github.com/rasbt/python-machine-learning-book/tree/master/code/optional-py-scripts">aquí</a>.</p>

<p>El código comienza declarando una clase <code class="highlighter-rouge">Perceptron</code> en la que se definen en constructor y tres métodos:</p>
<pre class="line-numbers">
  <code class="language-python">
    import numpy as np

    class Perceptron(object):
      def __init__(self, eta=0.01, n_iter=10):
        self.eta = eta
        self.n_iter = n_iter

      def fit(self, X, y):
        self.w_ = np.zeros(1 + X.shape[1])
        self.errors_ = []

        for _ in range(self.n_iter):
          errors = 0
          for xi, target in zip(X, y):
            update = self.eta * (target - self.predict(xi))
            self.w_[1:] += update * xi
            self.w_[0] += update
            errors += int(update != 0.0)
          self.errors_.append(errors)
        return self

      def net_input(self, X):
        return np.dot(X, self.w_[1:]) + self.w_[0]

      def predict(self, X):
        return np.where(self.net_input(X) &gt;= 0.0, 1, -1)
  </code>
</pre>

<p>Inicializamos el perceptrón con dos parámetros: <code class="highlighter-rouge">eta</code>, que es la tasa de aprendizaje, y <code class="highlighter-rouge">n_iter</code>, que es el número de veces que vamos a recorrer el conjunto de datos de entrenamiento. A cada una de estas veces se les llama “épocas”.</p>

<p>Una vez instanciado el perceptrón llamaremos al método <code class="highlighter-rouge">fit</code> para entrenar nuestro modelo. Se le pasan dos parámetros: una matriz <script type="math/tex">\bf X</script>, que contiene una fila por cada muestra y una columna por cada característica, y que constituye nuestro conjunto de datos de entrenamiento; y un array <script type="math/tex">\bf y</script>, que contiene el resultado objetivo para cada muestra.</p>

<p>Lo primero que hace el método <code class="highlighter-rouge">fit</code> es inicializar los pesos y los errores:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>  <span class="bp">self</span><span class="o">.</span><span class="n">w_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">errors_</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre>
</div>

<p>Los pesos se inicializan a un array con el mismo número de elementos que muestras tiene la matriz <script type="math/tex">\bf X</script> más uno. Ese más uno es debido a que vamos a almacenar también el parámetro <script type="math/tex">w_0</script> corresondiente al umbral <script type="math/tex">\theta</script> que pasamos a la izquiera en la equación \eqref{2.4}. Como estamos inicializando todo a cero consideramos el umbral inicial de activación como cero.</p>

<p>A continuación comienza un precose que se ejecutará <code class="highlighter-rouge">n_iter</code> veces. En el se itera sobre los datos proporcionados mediante esta instrucción:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>   <span class="k">for</span> <span class="n">xi</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre>
</div>

<p>Lo que va a hacer la instrucción <code class="highlighter-rouge">zip</code> es devolver un elemento por cada lista que se le pase de parámetro. Así, si <script type="math/tex">\bf X</script> es una matriz de 100 filas (muestras) y 2 columnas (características), e <script type="math/tex">\bf y</script> es un array de 100 elementos (las clases reales de cada muestra), la instrucción anterior iterará para cada muestra almacenando en <code class="highlighter-rouge">xi</code> las características y en <code class="highlighter-rouge">target</code> su clase real.</p>

<p>Con esos datos vamos a calcular los nuevos pesos. La fórmula era la siguiente:</p>

<script type="math/tex; mode=display">\Delta w_j = \eta(y^{(i)} - \hat y^{(i)})x_j^{(i)}
w_j := w_j + \Delta w_j</script>

<p>En nuestro caso hacemos esto:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>    <span class="n">update</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="n">target</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xi</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+=</span> <span class="n">update</span> <span class="o">*</span> <span class="n">xi</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">update</span>
    <span class="n">errors</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">update</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">)</span>
</code></pre>
</div>

<p>Calculamos primero el factor <script type="math/tex">\eta(y^{(i)} - \hat y^{(i)})</script>, y después lo multiplicamos por <script type="math/tex">\bf{x^{(i)}}</script> para sumárselo al array de pesos, salvo el peso 0. Al ser tanto ‘self.w_[1:]’ como ‘xi’ arrays con un elemento por cada característica, estamos aplicando la corrección a todos los pesos. En el peso <script type="math/tex">w_0</script> no multiplicamos por <script type="math/tex">\bf{x_0^{(i)}}</script>, ya que este por definición vale uno. Finalmente acumulamos el error de cada muestra, y al final de cada época lo añadimos a un array. Esto nos permitirá ver la evolución del error por épocas.</p>

<p>Veamos ahora cómo calcular el término <script type="math/tex">\hat y^{(i)}</script>, que en código se obtiene llamando a <code class="highlighter-rouge">self.predict(xi)</code></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>  <span class="k">def</span> <span class="nf">net_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xi</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xi</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net_input</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>

<p>Lo primero que hace <code class="highlighter-rouge">predict</code> con <code class="highlighter-rouge">xi</code> es usarlo para invocar <code class="highlighter-rouge">net_input</code>. En esta función usamos <code class="highlighter-rouge">np.dot</code> para realizar un producto escalar entre <code class="highlighter-rouge">xi</code> y <code class="highlighter-rouge">self.w_[1:]</code>. Es decir, suponiendo una muestra con dos características, y por tanto dos entradas y dos pesos, <code class="highlighter-rouge">np.dot(xi, self.w_[1:])</code> equivale a <script type="math/tex">w_1x_1 + w_2x_2</script>. A esto le sumamos <script type="math/tex">w_0</script> (ya que <script type="math/tex">x_0</script> es igual a uno), y tenemnos que <code class="highlighter-rouge">net_input</code> devuelve el valor <script type="math/tex">z</script>, tal como se define en \eqref{2.4}. La última parte, <code class="highlighter-rouge">np.where(self.net_input(xi) &gt;= 0.0, 1, -1)</code> devuelve 1 si <script type="math/tex">z</script> es mayor o igual que 0, y -1 en otro caso. En resumen, el método <code class="highlighter-rouge">predict</code> es la función <script type="math/tex">\phi(z)</script> (\eqref{2.5}).</p>

<h3 id="perceptrón-con-el-conjunto-de-datos-iris">Perceptrón con el conjunto de datos Iris</h3>

<p>Toda la lógica del perceptrón está implementada en la clase anterior. Vamos a utilizarla con el conjunto de datos Iris ya mencionado anteriormente. El ejemplo del libro utilizan la librería <code class="highlighter-rouge">pandas</code>, especializada en análisis de datos y estructuras, para cargar los datos de Iris. Estos datos se almacenan en un tipo de datos de la librería llamado <a href="http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe">DataFrame</a>:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://archive.ics.uci.edu/ml/'</span>
                 <span class="s">'machine-learning-databases/iris/iris.data'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">())</span>                
</code></pre>
</div>

<p>El archivo de datos lo estamos descargando de internet, pero también está disponible en el código de ejemplo para usar en local.</p>

<p>El código de ejemplo imprime las últimas líneas de la estructura de datos cargada:</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>145</strong></td>
      <td>6.7</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <td><strong>146</strong></td>
      <td>6.3</td>
      <td>2.5</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <td><strong>147</strong></td>
      <td>6.5</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <td><strong>148</strong></td>
      <td>6.2</td>
      <td>3.4</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <td><strong>149</strong></td>
      <td>5.9</td>
      <td>3.0</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>Iris-virginica</td>
    </tr>
  </tbody>
</table>

<p>A continuación preprocesamos los datos, para dejarlos en el formato adecuado para trabajar con ellos. Usaremos las librerías <code class="highlighter-rouge">numpy</code>, para tratar los datos, y <code class="highlighter-rouge">matplotlib</code>, para dibujarlos en una gráfica</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</code></pre>
</div>

<p>En primer lugar hemos seleccionado los 100 primeros registros del DataFrame, pero cogiendo sólo la quinta columna (la 4 por comenzar el índice en 0). Esto nos devuelve un array con 100 valores, cada uno de los cuales es el nombre de la especie. Es decir, cogemos las etiquetas de la clase de cada muestra.</p>

<p>En el conjunto de datos Iris los datos están ordenados de tal forma que los 50 primeros son Iris-setosa, y los 50 siguientes Iris-versicolor. De esta forma limitarnos a los 100 primeros registros nos permite realizar una clasificación binaria.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="s">'Iris-setosa'</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>

<p>El siguiente paso consiste en sustituir las etiquetas de texto por valores numéricos. El valor objetivo pasará a ser -1 para las Iris-setosa y 1 para las Iris-versicolor. Almacenamos los datos en un array <script type="math/tex">\bf y</script> de 100 elementos.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
</code></pre>
</div>

<p>De las cuatro características posibles nos vamos a quedar con dos: la longitud del sépalo y la longitud del pétalo. Esto nos permitirá dibujar los datos en una gráfica de dos dimensiones. Al igual que hicimos con el valor objetivo, cogemos los cien primeros valores del conjunto de datos, quedándonos con la primera y la tercera columna. Esto nos devuelve una matriz <script type="math/tex">\bf X \in \mathbb R^{100x2}</script>.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">50</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'setosa'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'x'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'versicolor'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'sepal length [cm]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'petal length [cm]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper left'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p>Dibujamos los datos almacenados. Marcamos con una ‘o’ roja las Iris-setosa (las 50 primeras), y con una ‘x’ azul las Iris-versicolor. El resultado es este:</p>

<div style="text-align:center">
    <figure>
        <img alt="Datos de entrenamiento" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_06.png" />
        <figcaption>Datos de entrenamiento</figcaption>
    </figure>
</div>

<p>Con los datos listos podemos realizar el entrenamiento.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">ppn</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ppn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre>
</div>

<p>Instanciamos el perceptrón con un <script type="math/tex">\eta = 0.1</script> y 10 épocas. Para entrenar  basta con llamar al método <code class="highlighter-rouge">fit</code> pasando <script type="math/tex">\bf X</script>  e <script type="math/tex">\bf y</script> como parámetros.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ppn</span><span class="o">.</span><span class="n">errors_</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ppn</span><span class="o">.</span><span class="n">errors_</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Number of updates'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c"># plt.savefig('./perceptron_1.png', dpi=300)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p>Una vez entrenado el modelo, pintamos en un gráfico los errores encontrados en cada generación. En  el eje X pintamos las épocas (la longitud del array de errores), y en el Y mostramos el número de errores.</p>

<div style="text-align:center">
    <figure>
        <img alt="Errores por época" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_07.png" />
        <figcaption>Errores por época</figcaption>
    </figure>
</div>

<p>A partir de la 6ª época el modelo ya no comete errores. Ahora vamos a dibujar los datos de entrenamiento, pero marcando las zonas que el modelo ya entrenado considera como de una clase u otra.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>

<span class="k">def</span> <span class="nf">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="n">markers</span> <span class="o">=</span> <span class="p">(</span><span class="s">'s'</span><span class="p">,</span> <span class="s">'x'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="s">'^'</span><span class="p">,</span> <span class="s">'v'</span><span class="p">)</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">(</span><span class="s">'red'</span><span class="p">,</span> <span class="s">'blue'</span><span class="p">,</span> <span class="s">'lightgreen'</span><span class="p">,</span> <span class="s">'gray'</span><span class="p">,</span> <span class="s">'cyan'</span><span class="p">)</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">colors</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))])</span>
</code></pre>
</div>

<p>Definimos una nueva función que nos permita dibujar en distintos colores las zonas que serían de Iris-setosa e Iris-versicolor si una muestra tuviese unas características que estuviesen en ese punto.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="c"># ... Continuación</span>
    <span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">xx1</span><span class="p">,</span> <span class="n">xx2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">),</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xx1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">xx2</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx1</span><span class="p">,</span> <span class="n">xx2</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xx1</span><span class="o">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">xx1</span><span class="o">.</span><span class="nb">max</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">xx2</span><span class="o">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">xx2</span><span class="o">.</span><span class="nb">max</span><span class="p">())</span>

    <span class="c"># plot class samples</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">cl</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">cl</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">cmap</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                    <span class="n">marker</span><span class="o">=</span><span class="n">markers</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">cl</span><span class="p">)</span>
</code></pre>
</div>
<p>Definimos los valores mínimo y máximo del sépalo (<code class="highlighter-rouge">x1_min</code> y <code class="highlighter-rouge">x1_max</code>) y del pétalo (<code class="highlighter-rouge">x2_min</code> y <code class="highlighter-rouge">x2_max</code>), restando uno al mínimo y sumándolo al máximo para tener un rango con margen. La función <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html"><code class="highlighter-rouge">np.arange</code></a> devuelve una lista de valores que van del primer parámetro al segundo en intervalos marcados por el tercer parámetro. Las dos llamadas a <code class="highlighter-rouge">np.arange</code> devolverán un array de valores separados por 0.02. En el primer caso van del 3.30 al 7.98, en el segundo del 0 al 6.08.  Con ambos arrays construimos una matriz que pasamos al predictor, el cual nos devolverá el valor predicho para todos los puntos del plano definido.</p>

<div style="text-align:center">
    <figure>
        <img alt="Regiones predichas para cada clase" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch02/images/02_08.png" />
        <figcaption>Regiones predichas para cada clase</figcaption>
    </figure>
</div>


			<div class="blog-navigation">
				
					<a class="prev" href="/2017/03/12/python-machine-learning-i/">&laquo; Machine Learning con Python - Tema 1</a>
				
				
					<a class="next" href="/2017/03/26/materia-oscura-blake-crouch/">Materia oscura &raquo;</a>
				
			</div>


			
				<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    
    var disqus_config = function () {
        this.page.url = "http://www.javiercancela.com/2017/03/19/python-machine-learning-ii/";  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = "/2017/03/19/python-machine-learning-ii"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        
        s.src = '//javiercancela.disqus.com/embed.js';
        
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			
		</div>
	</div>
</section>



		<footer>
			<div class="container">
				<p class="editor-link"><a href="cloudcannon:collections/_data/footer.yml" class="btn"><strong>&#9998;</strong> Edit footer</a></p>
				<ul class="footer-left-links">
					
						<li>
							<a  href="/" >
								
								Blog
							</a>
						</li>
					
						<li>
							<a  href="/archivo/" >
								
								Archivo
							</a>
						</li>
					
						<li>
							<a  href="/sobre-mi/" >
								
								Sobre mí
							</a>
						</li>
					
				</ul>
				<ul class="footer-right-links">
					
						<li>
							<a target="_blank" href="https://twitter.com/jcanvic" class="twitter-icon">
								
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M22.46,6C21.69,6.35 20.86,6.58 20,6.69C20.88,6.16 21.56,5.32 21.88,4.31C21.05,4.81 20.13,5.16 19.16,5.36C18.37,4.5 17.26,4 16,4C13.65,4 11.73,5.92 11.73,8.29C11.73,8.63 11.77,8.96 11.84,9.27C8.28,9.09 5.11,7.38 3,4.79C2.63,5.42 2.42,6.16 2.42,6.94C2.42,8.43 3.17,9.75 4.33,10.5C3.62,10.5 2.96,10.3 2.38,10C2.38,10 2.38,10 2.38,10.03C2.38,12.11 3.86,13.85 5.82,14.24C5.46,14.34 5.08,14.39 4.69,14.39C4.42,14.39 4.15,14.36 3.89,14.31C4.43,16 6,17.26 7.89,17.29C6.43,18.45 4.58,19.13 2.56,19.13C2.22,19.13 1.88,19.11 1.54,19.07C3.44,20.29 5.7,21 8.12,21C16,21 20.33,14.46 20.33,8.79C20.33,8.6 20.33,8.42 20.32,8.23C21.16,7.63 21.88,6.87 22.46,6Z" /></svg>
	
								
							</a>
						</li>
					
						<li>
							<a target="_blank" href="https://www.linkedin.com/in/javiercancela" class="linkedin-icon">
								
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M19,19H16V13.7A1.5,1.5 0 0,0 14.5,12.2A1.5,1.5 0 0,0 13,13.7V19H10V10H13V11.2C13.5,10.36 14.59,9.8 15.5,9.8A3.5,3.5 0 0,1 19,13.3M6.5,8.31C5.5,8.31 4.69,7.5 4.69,6.5A1.81,1.81 0 0,1 6.5,4.69C7.5,4.69 8.31,5.5 8.31,6.5A1.81,1.81 0 0,1 6.5,8.31M8,19H5V10H8M20,2H4C2.89,2 2,2.89 2,4V20A2,2 0 0,0 4,22H20A2,2 0 0,0 22,20V4C22,2.89 21.1,2 20,2Z" /></svg>
	
								
							</a>
						</li>
					
						<li>
							<a target="_blank" href="https://plus.google.com/+JavierCancelaVicente" class="google-plus-icon">
								
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M23,11H21V9H19V11H17V13H19V15H21V13H23M8,11V13.4H12C11.8,14.4 10.8,16.4 8,16.4C5.6,16.4 3.7,14.4 3.7,12C3.7,9.6 5.6,7.6 8,7.6C9.4,7.6 10.3,8.2 10.8,8.7L12.7,6.9C11.5,5.7 9.9,5 8,5C4.1,5 1,8.1 1,12C1,15.9 4.1,19 8,19C12,19 14.7,16.2 14.7,12.2C14.7,11.7 14.7,11.4 14.6,11H8Z" /></svg>
	
								
							</a>
						</li>
					
						<li>
							<a  href="/feed.xml" class="rss-icon">
								
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"/><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
	
								
							</a>
						</li>
					
				</ul>
				<p class="copyright">
					<a href="https://cloudcannon.com/">
						Template by CloudCannon
					</a>
				</p>
			</div>
		</footer>

		<script src="//ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
		<script src="/js/main.js"></script>
		<script src="/js/prism.js"></script>
		<script id="dsq-count-scr" src="//javiercancela.disqus.com/count.js" async></script>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
		<script type="text/javascript">
			MathJax.Hub.Config({
				config: ["MMLorHTML.js"],
				extensions: ["tex2jax.js"],
				jax: ["input/TeX"],
				displayAlign: "center",
				tex2jax: {
					inlineMath: [ ['$','$'], ["\\(","\\)"] ],
					displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
					processEscapes: false
				},
				TeX: {
					extensions: ["AMSmath.js", "AMSsymbols.js"],
					TagSide: "right",
					TagIndent: ".8em",
					MultLineWidth: "85%",
					equationNumbers: {
						autoNumber: "AMS",
					},
					unicode: {
						fonts: "STIXGeneral,'Arial Unicode MS'"
					}
				},
				showProcessingMessages: false
			});
		</script>		
	</body>
</html>
