<!DOCTYPE html>

<html lang="en">
	<head>
		<script type="text/javascript">
		    var host = "www.javiercancela.com";
		    if ((host == window.location.host) && (window.location.protocol != "https:"))
		        window.location.protocol = "https";
		</script>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="generator" content="Jekyll v3.3.1">

		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300|Rubik:300">
		<link rel="stylesheet" href="/css/screen.css">
		<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
		<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
		<link rel="manifest" href="/manifest.json">
		<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
		<meta name="theme-color" content="#ffffff">

		<!-- Begin Jekyll SEO tag v2.1.0 -->
<title>Machine Learning con Python - Tema 3 - Introducción a Scikit-learn - Página de Javier Cancela</title>
<meta property="og:title" content="Machine Learning con Python - Tema 3 - Introducción a Scikit-learn" />
<meta name="description" content="Notas sobre el libro “Python Machine Learning”, de Sebastian Raschka" />
<meta property="og:description" content="Notas sobre el libro “Python Machine Learning”, de Sebastian Raschka" />
<link rel="canonical" href="https://www.javiercancela.com/2017/04/23/python-machine-learning-v/" />
<meta property="og:url" content="https://www.javiercancela.com/2017/04/23/python-machine-learning-v/" />
<meta property="og:site_name" content="Página de Javier Cancela" />
<meta property="og:image" content="https://www.javiercancela.com/images/pml/pml.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-04-23T01:00:00+00:00" />
<script type="application/ld+json">
{"@context": "http://schema.org",
"@type": "BlogPosting",
"headline": "Machine Learning con Python - Tema 3 - Introducción a Scikit-learn",
"image": "https://www.javiercancela.com/images/pml/pml.jpg",
"datePublished": "2017-04-23T01:00:00+00:00",
"description": "Notas sobre el libro “Python Machine Learning”, de Sebastian Raschka",
"publisher": {"@type": "Organization",
"logo": {"@type": "ImageObject",
"url": "https://www.javiercancela.com/siteicon.png"}},
"url": "https://www.javiercancela.com/2017/04/23/python-machine-learning-v/"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="https://www.javiercancela.com/feed.xml" title="Página de Javier Cancela" />

		
			<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-58458863-1', 'auto');
  ga('send', 'pageview');

</script>
		
	</head>

	<body>
		<header id="mainHeader">
			<div class="container">
				<div class="company-name">
					<a href="/">
						<span class="dark-logo"><img width="104" height="38" src="/images/logo/dark.png" alt="dark frisco logo"></span>
						<span class="light-logo"><img width="104" height="38" src="/images/logo/light.png" alt="light frisco logo"></span>
					</a>
				</div>
				<nav>
	<a class="nav-toggle" id="open-nav" href="#">&#9776;</a>
	
		
		

		
		<a href="/" class="" >Blog</a>
	
		
		

		
		<a href="/archivo/" class="" >Archivo</a>
	
		
		

		
		<a href="/sobre-mi/" class="" >Sobre mí</a>
	
</nav>

			</div>
		</header>

		<section class="hero" style="background-image: url(/images/pml/pml.jpg)">
	<div class="inner-hero text-container">
		<div class="hero-text-container">
			<h1>Machine Learning con Python - Tema 3 - Introducción a Scikit-learn</h1>
			<p class="subtext">Notas sobre el libro "Python Machine Learning", de Sebastian Raschka</p>
		</div>
	</div>
</section>

<section>
	<div class="blog-post text-container">
		<p class="post-details">
	
		
		<span class="blog-filter">
			<a href="/category/python/">Python</a>
		</span>
	
		
		<span class="blog-filter">
			<a href="/category/libros/">Libros</a>
		</span>
	
		
		<span class="blog-filter">
			<a href="/category/machine-learning/">Machine Learning</a>
		</span>
	
		
		<span class="blog-filter">
			<a href="/category/inteligencia-artificial/">Inteligencia Artificial</a>
		</span>
	
	
	
	
	
	
	
	<span class="post-date">23 de abril de 2017</span>
</p>


		<div class="post-content">
			<p>El propósito del tema 3 es revisar algoritmos comunes de aprendizaje máquina. Las diferencias existentes entre estos algoritmos hacen que cada uno sea más adecuado para unas tareas que para otras. En unos casos el criterio de elección será la naturaleza de nuestros datos (número de características, ruido, separabilidad lineal,…), mientras que en otros nos basaremos en la direfencia de rendimientos.</p>

<p>Como paso previo el libro realiza una presentación de <a href="http://scikit-learn.org/stable/index.html"><em>scikit-learn</em></a>, una librería para Python que incluye varios de los algoritmos más usados en <em>machine learning</em>. El código de esta librería es abierto y <a href="https://github.com/scikit-learn/scikit-learn">está disponible en GitHub</a>.</p>

<h2 id="perceptrón-con-scikit-learn">Perceptrón con <em>scikit-learn</em></h2>

<p>Para empezar con la librería, el libro vuelve al Perceptrón con el conjunto de datos Iris. La librería <em>scikit-learn</em> incluye varios conjuntos de datos, así que usaremos el conjunto Iris incluido en la librería. Dividiremos el conjunto en un grupo de datos para el entrenamiento y otro para la validación.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre>
</div>

<p>Cargamos los datos de la librería y hacemos un <em>slice</em> de dos de las columnas (dos caracterísiticas) para cargar los datos en la matriz <code class="highlighter-rouge">X</code>. La librería nos permite acceder directamente a las clases reales de cada muestra a través de <code class="highlighter-rouge">iris.target</code>, donde los valores para <em>Iris-Setosa</em>, <em>Iris-Versicolor</em> e <em>Iris-Virginica</em> están almacenados como 0, 1 y 2.</p>

<p>El método <code class="highlighter-rouge">train_test_split</code> reparte el 30% de los datos (<code class="highlighter-rouge">test_size=0.3</code>) para las pruebas, de forma aleatoria (al fijar un <em>seed</em> a través de <code class="highlighter-rouge">random_state=0</code> garantizamos que el reparto pseudoaleatorio sea el mismo en cada ejecución). El resultado será una matriz <code class="highlighter-rouge">X_test</code> con 45 elementos, y un array <code class="highlighter-rouge">y_test</code> con las 45 clases correspondientes. <code class="highlighter-rouge">X_train</code> e <code class="highlighter-rouge">y_train</code> contendrán el resto de los datos para el entrenamiento.</p>

<h3 id="escalado-de-características">Escalado de características</h3>

<p>Como mencionamos en la entrada anterior, el escalado de características es una técnica básica para la optimización del proceso de entrenamiento. El libro utiliza la clase <code class="highlighter-rouge">StandardScaler</code> para ilustrar esta técnica:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_std</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_std</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre>
</div>

<p>La clase <code class="highlighter-rouge">StandardScaler</code> contiene un método <code class="highlighter-rouge">fit</code> que permite estimar los parámetros necesarios para la estandarización. A partir de los datos de entrenamiento proporcionados, el método estimará la media (<script type="math/tex">\mu</script>) y la <a href="https://es.wikipedia.org/wiki/Desviaci%C3%B3n_t%C3%ADpica">desviación estándar</a> (<script type="math/tex">\sigma</script>). Con ellas el método <code class="highlighter-rouge">transform</code> generará nuestros nuevos conjuntos de datos de entrenamiento y de pruebas estandarizados. Tras la estandarización, las características pasan a tener valores positivos y negativos, siguiendo una distribución casi normal centrada en el cero:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="nb">max</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">13</span><span class="p">]:</span> <span class="mf">1.7101884052506424</span>

<span class="nb">max</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">14</span><span class="p">]:</span> <span class="mf">1.6373128028016599</span>

<span class="nb">min</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">15</span><span class="p">]:</span> <span class="o">-</span><span class="mf">1.5192836530366176</span>

<span class="nb">min</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">16</span><span class="p">]:</span> <span class="o">-</span><span class="mf">1.4487217993375945</span>
</code></pre>
</div>

<h3 id="la-clase--con-one-vs-rest">La clase <code class="highlighter-rouge">Perceptron</code> con <em>one-vs.-rest</em></h3>

<p>Una diferencia de la clase <code class="highlighter-rouge">Perceptron</code> de <code class="highlighter-rouge">scikit-learn</code> con la implementada en el capítulo 2 del libro es que la que vamos a ver ahora soporta clasificaciones multiclase. En el capítulo 2 restringimos nuestro conjunto de datos a muestras de solo dos clases, ya que el algoritmo sólo era capaz de distinguir si una muestra pertenecía a una clase o no. Si la función de activación superaba un umbral se asignaba una clase, si no, se asignaba la otra.</p>

<p>Esta función de activación es inherente al Perceptrón. Sin embargo, aun con ella es posible realizar clasificaciones multiclase. Para ello se utiliza una estrategia llamada ‘Uno contra los demás’ (<em>one-vs.-rest</em>, <em>OvR</em>). En esta estrategia se entrena un clasificador para cada clase. Es decir, en nuestro conjunto de datos con tres variantes de Iris, en vez de usar el Perceptrón para entrenar un clasificador que nos diga si una muestra es <em>Iris-setosa</em> o <em>Iris-versicolor</em>, entrenaremos un clasificador que nos diga si una muestra es <em>Iris-setosa</em> o no, otro que nos diga si una muestra es <em>Iris-versicolor</em> o no, y otro que haga lo mismo con <em>Iris-virginica</em>.</p>

<p>La clasificación se realiza evaluando cada muestra con cada clasificador. Estos nos dirán si la muestra pertenece a su clase o no. Para poder resolver ambigüedades (una muestra que esté en más de una clase, o que no esté en ninguna), los clasificadores no devuelven una etiqueta, sino una puntuación de confianza que indica cómo de seguro está el clasificador de que una muestra pertenece a la clase evaluada. Así, cuando queremos predecir la clase de una muestra nueva nos quedamos con la clase a la que corresponde la puntuación de confianza más alta.</p>

<p>El código Python para hacer esto es muy simple:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Perceptron</span>

<span class="n">ppn</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">eta0</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ppn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre>
</div>

<p>La clase <code class="highlighter-rouge">Perceptron</code> admite muchos parámetros en el constructor. Los parámetros <code class="highlighter-rouge">n_iter</code> y <code class="highlighter-rouge">eta0</code> establecen el número de épocas y la tasa de aprendizaje, como ya vimos en entradas anteriores. Por defecto, la clase <code class="highlighter-rouge">Perceptron</code> baraja los datos de entrenamiento después de cada época. Para ello usa un generador de números pseudoaleatorios, cuya semilla se puede definir con el parámetro <code class="highlighter-rouge">random_state</code>. Al fijar este parámetro provocamos que los números aleatorios generados sean siempre los mismos en cada ejecución del código, de forma que siempre que los clasificadores obtenidos sean siempre los mismos.</p>

<p>El <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch03/ch03.ipynb">código del libro</a> prosigue mostrando los resultados del entrenamiento: de los datos de prueba se clasifican incorrectamente 4 muestras de 45, es decir, un porcentaje de acierto del 91%:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">ppn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_std</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Misclassified samples: </span><span class="si">%</span><span class="s">d'</span> <span class="o">%</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">())</span>
<span class="c"># Imprime: Misclassified samples: 4</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy: </span><span class="si">%.2</span><span class="s">f'</span> <span class="o">%</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="c"># Imprime: Accuracy: 0.91</span>
</code></pre>
</div>

<p>Para finalizar este apartado, el autor modifica el método <code class="highlighter-rouge">plot_decision_regions</code>, visto en entradas anteriores, para que resalte los datos de prueba con círculos. El código se puede ver <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch03/ch03.ipynb">aquí</a>.</p>

<div style="text-align:center">
    <figure>
        <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch03/images/03_01.png">
        <img alt="No es posible realizar una separación perfecta de los tres conjuntos de datos" src="https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/ch03/images/03_01.png" /></a>
        <figcaption>Como se ven en la gráfica, no es posible realizar una separación perfecta de los tres conjuntos de datos (no se puede dibujar una recta que separe todos los círculos verdes de todas las cruces azules)</figcaption>
    </figure>
</div>


			<div class="blog-navigation">
				
					<a class="prev" href="/2017/04/16/pausa-por-vacaciones/">&laquo; Pausa por vacaciones</a>
				
				
			</div>


			
				<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    
    var disqus_config = function () {
        this.page.url = "http://www.javiercancela.com/2017/04/23/python-machine-learning-v/";  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = "/2017/04/23/python-machine-learning-v"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        
        s.src = '//javiercancela.disqus.com/embed.js';
        
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			
		</div>
	</div>
</section>



		<footer>
			<div class="container">
				<p class="editor-link"><a href="cloudcannon:collections/_data/footer.yml" class="btn"><strong>&#9998;</strong> Edit footer</a></p>
				<ul class="footer-left-links">
					
						<li>
							<a  href="/" >
								
								Blog
							</a>
						</li>
					
						<li>
							<a  href="/archivo/" >
								
								Archivo
							</a>
						</li>
					
						<li>
							<a  href="/sobre-mi/" >
								
								Sobre mí
							</a>
						</li>
					
				</ul>
				<ul class="footer-right-links">
					
						<li>
							<a target="_blank" href="https://twitter.com/jcanvic" class="twitter-icon">
								
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M22.46,6C21.69,6.35 20.86,6.58 20,6.69C20.88,6.16 21.56,5.32 21.88,4.31C21.05,4.81 20.13,5.16 19.16,5.36C18.37,4.5 17.26,4 16,4C13.65,4 11.73,5.92 11.73,8.29C11.73,8.63 11.77,8.96 11.84,9.27C8.28,9.09 5.11,7.38 3,4.79C2.63,5.42 2.42,6.16 2.42,6.94C2.42,8.43 3.17,9.75 4.33,10.5C3.62,10.5 2.96,10.3 2.38,10C2.38,10 2.38,10 2.38,10.03C2.38,12.11 3.86,13.85 5.82,14.24C5.46,14.34 5.08,14.39 4.69,14.39C4.42,14.39 4.15,14.36 3.89,14.31C4.43,16 6,17.26 7.89,17.29C6.43,18.45 4.58,19.13 2.56,19.13C2.22,19.13 1.88,19.11 1.54,19.07C3.44,20.29 5.7,21 8.12,21C16,21 20.33,14.46 20.33,8.79C20.33,8.6 20.33,8.42 20.32,8.23C21.16,7.63 21.88,6.87 22.46,6Z" /></svg>
	
								
							</a>
						</li>
					
						<li>
							<a target="_blank" href="https://www.linkedin.com/in/javiercancela" class="linkedin-icon">
								
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M19,19H16V13.7A1.5,1.5 0 0,0 14.5,12.2A1.5,1.5 0 0,0 13,13.7V19H10V10H13V11.2C13.5,10.36 14.59,9.8 15.5,9.8A3.5,3.5 0 0,1 19,13.3M6.5,8.31C5.5,8.31 4.69,7.5 4.69,6.5A1.81,1.81 0 0,1 6.5,4.69C7.5,4.69 8.31,5.5 8.31,6.5A1.81,1.81 0 0,1 6.5,8.31M8,19H5V10H8M20,2H4C2.89,2 2,2.89 2,4V20A2,2 0 0,0 4,22H20A2,2 0 0,0 22,20V4C22,2.89 21.1,2 20,2Z" /></svg>
	
								
							</a>
						</li>
					
						<li>
							<a target="_blank" href="https://plus.google.com/+JavierCancelaVicente" class="google-plus-icon">
								
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M23,11H21V9H19V11H17V13H19V15H21V13H23M8,11V13.4H12C11.8,14.4 10.8,16.4 8,16.4C5.6,16.4 3.7,14.4 3.7,12C3.7,9.6 5.6,7.6 8,7.6C9.4,7.6 10.3,8.2 10.8,8.7L12.7,6.9C11.5,5.7 9.9,5 8,5C4.1,5 1,8.1 1,12C1,15.9 4.1,19 8,19C12,19 14.7,16.2 14.7,12.2C14.7,11.7 14.7,11.4 14.6,11H8Z" /></svg>
	
								
							</a>
						</li>
					
						<li>
							<a  href="/feed.xml" class="rss-icon">
								
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"/><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
	
								
							</a>
						</li>
					
				</ul>
				<p class="copyright">
					<a href="https://cloudcannon.com/">
						Template by CloudCannon
					</a>
				</p>
			</div>
		</footer>

		<script src="//ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
		<script src="/js/main.js"></script>
		<script src="/js/prism.js"></script>
		<script id="dsq-count-scr" src="//javiercancela.disqus.com/count.js" async></script>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
		<script type="text/javascript">
			MathJax.Hub.Config({
				config: ["MMLorHTML.js"],
				extensions: ["tex2jax.js"],
				jax: ["input/TeX"],
				displayAlign: "center",
				tex2jax: {
					inlineMath: [ ['$','$'], ["\\(","\\)"] ],
					displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
					processEscapes: false
				},
				TeX: {
					extensions: ["AMSmath.js", "AMSsymbols.js"],
					TagSide: "right",
					TagIndent: ".8em",
					MultLineWidth: "85%",
					equationNumbers: {
						autoNumber: "AMS",
					},
					unicode: {
						fonts: "STIXGeneral,'Arial Unicode MS'"
					}
				},
				showProcessingMessages: false
			});
		</script>		
	</body>
</html>
